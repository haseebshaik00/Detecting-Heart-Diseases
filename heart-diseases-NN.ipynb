{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeartDiseases_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrGTnXJQyWeMT6cBJLtlIq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatchaturvedi28/Heart-Disease-Prediction/blob/master/HeartDiseases_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7km_Cy45YxX",
        "colab_type": "code",
        "outputId": "48907699-d5d2-4055-c755-0bb6d0db88ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.27.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP1dWTCh5iIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JeaPvP6NSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import, unicode_literals\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHoQMhaS6gbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAxpyMGg6quF",
        "colab_type": "code",
        "outputId": "36a9f2a5-9bae-4206-b864-ed013080affb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 41
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3de0f892-bb50-4279-8eea-53e1cc67e1b7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3de0f892-bb50-4279-8eea-53e1cc67e1b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbDOfsPg7AlA",
        "colab_type": "code",
        "outputId": "83fbe5a4-9425-4726-82c3-118267253291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data = pd.read_csv('heart.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "3   56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
              "4   57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaPv-qxT7dwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data.iloc[:, :-1]\n",
        "target = data.pop('target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elxwm-2a73So",
        "colab_type": "code",
        "outputId": "c03b590f-125c-4853-fb15-75f444d2f51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "298   57    0   0       140   241  ...      1      0.2      1   0     3\n",
              "299   45    1   3       110   264  ...      0      1.2      1   0     3\n",
              "300   68    1   0       144   193  ...      0      3.4      1   2     3\n",
              "301   57    1   0       130   131  ...      1      1.2      1   1     3\n",
              "302   57    0   1       130   236  ...      0      0.0      1   1     2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07FWARXV76HY",
        "colab_type": "code",
        "outputId": "38f07b48-44b3-4c5e-dfa1-27138276cf4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "target = pd.DataFrame(target, columns=['target'])\n",
        "target.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target\n",
              "298       0\n",
              "299       0\n",
              "300       0\n",
              "301       0\n",
              "302       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOWd6UVx7Q_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_label, test_label = train_test_split(df, target, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNAeGi4X8xEs",
        "colab_type": "code",
        "outputId": "0de48a97-6949-4f08-8f54-e4c9cc8afa82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsaFy-CJ8zgS",
        "colab_type": "code",
        "outputId": "db5337ce-dfb6-469b-be2f-3841b498db0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzV6qDXP8_g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(13,)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEnrkN2Q9soG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDQktBY598bE",
        "colab_type": "code",
        "outputId": "fa93992e-1314-4f21-be83-05284a6398bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_data, train_label, epochs=100, batch_size=32, verbose=1, validation_data=(test_data, test_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "Train on 227 samples, validate on 76 samples\n",
            "Epoch 1/100\n",
            "227/227 [==============================] - 0s 547us/sample - loss: 3.2821 - accuracy: 0.5463 - val_loss: 1.2556 - val_accuracy: 0.5395\n",
            "Epoch 2/100\n",
            "227/227 [==============================] - 0s 90us/sample - loss: 1.0362 - accuracy: 0.5903 - val_loss: 0.8404 - val_accuracy: 0.5526\n",
            "Epoch 3/100\n",
            "227/227 [==============================] - 0s 109us/sample - loss: 0.8548 - accuracy: 0.6256 - val_loss: 0.5533 - val_accuracy: 0.7105\n",
            "Epoch 4/100\n",
            "227/227 [==============================] - 0s 92us/sample - loss: 0.6957 - accuracy: 0.6828 - val_loss: 0.7976 - val_accuracy: 0.5263\n",
            "Epoch 5/100\n",
            "227/227 [==============================] - 0s 105us/sample - loss: 0.7139 - accuracy: 0.5903 - val_loss: 0.7012 - val_accuracy: 0.5789\n",
            "Epoch 6/100\n",
            "227/227 [==============================] - 0s 90us/sample - loss: 0.6588 - accuracy: 0.6696 - val_loss: 0.6552 - val_accuracy: 0.6184\n",
            "Epoch 7/100\n",
            "227/227 [==============================] - 0s 90us/sample - loss: 0.6022 - accuracy: 0.6784 - val_loss: 0.5391 - val_accuracy: 0.7105\n",
            "Epoch 8/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.5476 - accuracy: 0.7093 - val_loss: 0.5258 - val_accuracy: 0.7632\n",
            "Epoch 9/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.5380 - accuracy: 0.7048 - val_loss: 1.0007 - val_accuracy: 0.5789\n",
            "Epoch 10/100\n",
            "227/227 [==============================] - 0s 96us/sample - loss: 0.7631 - accuracy: 0.6564 - val_loss: 1.0828 - val_accuracy: 0.5789\n",
            "Epoch 11/100\n",
            "227/227 [==============================] - 0s 103us/sample - loss: 0.7527 - accuracy: 0.6432 - val_loss: 0.9854 - val_accuracy: 0.5789\n",
            "Epoch 12/100\n",
            "227/227 [==============================] - 0s 152us/sample - loss: 0.8267 - accuracy: 0.6167 - val_loss: 0.6740 - val_accuracy: 0.6579\n",
            "Epoch 13/100\n",
            "227/227 [==============================] - 0s 117us/sample - loss: 0.7021 - accuracy: 0.6740 - val_loss: 0.5842 - val_accuracy: 0.6974\n",
            "Epoch 14/100\n",
            "227/227 [==============================] - 0s 98us/sample - loss: 0.5528 - accuracy: 0.7137 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "227/227 [==============================] - 0s 92us/sample - loss: 0.5583 - accuracy: 0.7137 - val_loss: 0.6168 - val_accuracy: 0.6711\n",
            "Epoch 16/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.6286 - accuracy: 0.6652 - val_loss: 0.9299 - val_accuracy: 0.5789\n",
            "Epoch 17/100\n",
            "227/227 [==============================] - 0s 95us/sample - loss: 0.7058 - accuracy: 0.6520 - val_loss: 0.5355 - val_accuracy: 0.7237\n",
            "Epoch 18/100\n",
            "227/227 [==============================] - 0s 106us/sample - loss: 0.6034 - accuracy: 0.6564 - val_loss: 0.8963 - val_accuracy: 0.5132\n",
            "Epoch 19/100\n",
            "227/227 [==============================] - 0s 89us/sample - loss: 0.8164 - accuracy: 0.5727 - val_loss: 0.9013 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "227/227 [==============================] - 0s 89us/sample - loss: 0.7226 - accuracy: 0.6123 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.6366 - accuracy: 0.6652 - val_loss: 0.6041 - val_accuracy: 0.6842\n",
            "Epoch 22/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.5307 - accuracy: 0.7225 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.5595 - accuracy: 0.6872 - val_loss: 0.7286 - val_accuracy: 0.6184\n",
            "Epoch 24/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.5311 - accuracy: 0.7401 - val_loss: 0.4930 - val_accuracy: 0.7895\n",
            "Epoch 25/100\n",
            "227/227 [==============================] - 0s 89us/sample - loss: 0.5003 - accuracy: 0.7533 - val_loss: 0.8586 - val_accuracy: 0.6053\n",
            "Epoch 26/100\n",
            "227/227 [==============================] - 0s 88us/sample - loss: 0.8518 - accuracy: 0.5551 - val_loss: 0.9600 - val_accuracy: 0.5789\n",
            "Epoch 27/100\n",
            "227/227 [==============================] - 0s 96us/sample - loss: 0.6901 - accuracy: 0.6432 - val_loss: 0.7726 - val_accuracy: 0.6316\n",
            "Epoch 28/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.6462 - accuracy: 0.6784 - val_loss: 0.6233 - val_accuracy: 0.7105\n",
            "Epoch 29/100\n",
            "227/227 [==============================] - 0s 89us/sample - loss: 0.5411 - accuracy: 0.7093 - val_loss: 0.6523 - val_accuracy: 0.6842\n",
            "Epoch 30/100\n",
            "227/227 [==============================] - 0s 97us/sample - loss: 0.6013 - accuracy: 0.7357 - val_loss: 0.7383 - val_accuracy: 0.6184\n",
            "Epoch 31/100\n",
            "227/227 [==============================] - 0s 92us/sample - loss: 0.6650 - accuracy: 0.6872 - val_loss: 0.5464 - val_accuracy: 0.7368\n",
            "Epoch 32/100\n",
            "227/227 [==============================] - 0s 116us/sample - loss: 0.5128 - accuracy: 0.7445 - val_loss: 0.4855 - val_accuracy: 0.8026\n",
            "Epoch 33/100\n",
            "227/227 [==============================] - 0s 99us/sample - loss: 0.4743 - accuracy: 0.7621 - val_loss: 0.5667 - val_accuracy: 0.7368\n",
            "Epoch 34/100\n",
            "227/227 [==============================] - 0s 94us/sample - loss: 0.6518 - accuracy: 0.6696 - val_loss: 0.4634 - val_accuracy: 0.7895\n",
            "Epoch 35/100\n",
            "227/227 [==============================] - 0s 97us/sample - loss: 0.4621 - accuracy: 0.7885 - val_loss: 0.5075 - val_accuracy: 0.7895\n",
            "Epoch 36/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.5164 - accuracy: 0.7093 - val_loss: 0.5001 - val_accuracy: 0.7763\n",
            "Epoch 37/100\n",
            "227/227 [==============================] - 0s 86us/sample - loss: 0.4491 - accuracy: 0.8194 - val_loss: 0.5088 - val_accuracy: 0.7632\n",
            "Epoch 38/100\n",
            "227/227 [==============================] - 0s 109us/sample - loss: 0.4636 - accuracy: 0.7930 - val_loss: 0.6230 - val_accuracy: 0.6974\n",
            "Epoch 39/100\n",
            "227/227 [==============================] - 0s 109us/sample - loss: 0.4797 - accuracy: 0.7577 - val_loss: 0.8223 - val_accuracy: 0.6184\n",
            "Epoch 40/100\n",
            "227/227 [==============================] - 0s 109us/sample - loss: 0.6280 - accuracy: 0.6828 - val_loss: 0.6311 - val_accuracy: 0.7105\n",
            "Epoch 41/100\n",
            "227/227 [==============================] - 0s 115us/sample - loss: 0.4529 - accuracy: 0.7930 - val_loss: 0.7771 - val_accuracy: 0.6053\n",
            "Epoch 42/100\n",
            "227/227 [==============================] - 0s 115us/sample - loss: 0.5605 - accuracy: 0.7357 - val_loss: 0.5347 - val_accuracy: 0.7105\n",
            "Epoch 43/100\n",
            "227/227 [==============================] - 0s 99us/sample - loss: 0.4470 - accuracy: 0.7885 - val_loss: 0.5087 - val_accuracy: 0.7368\n",
            "Epoch 44/100\n",
            "227/227 [==============================] - 0s 109us/sample - loss: 0.4906 - accuracy: 0.7577 - val_loss: 0.5776 - val_accuracy: 0.7237\n",
            "Epoch 45/100\n",
            "227/227 [==============================] - 0s 84us/sample - loss: 0.6246 - accuracy: 0.7225 - val_loss: 0.4574 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "227/227 [==============================] - 0s 83us/sample - loss: 0.4323 - accuracy: 0.7930 - val_loss: 0.4529 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.4082 - accuracy: 0.8150 - val_loss: 0.4564 - val_accuracy: 0.8026\n",
            "Epoch 48/100\n",
            "227/227 [==============================] - 0s 90us/sample - loss: 0.4021 - accuracy: 0.8414 - val_loss: 0.4683 - val_accuracy: 0.7895\n",
            "Epoch 49/100\n",
            "227/227 [==============================] - 0s 88us/sample - loss: 0.4050 - accuracy: 0.7974 - val_loss: 0.5924 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.4363 - accuracy: 0.8106 - val_loss: 0.4378 - val_accuracy: 0.7763\n",
            "Epoch 51/100\n",
            "227/227 [==============================] - 0s 89us/sample - loss: 0.3913 - accuracy: 0.8150 - val_loss: 0.4569 - val_accuracy: 0.8158\n",
            "Epoch 52/100\n",
            "227/227 [==============================] - 0s 98us/sample - loss: 0.4566 - accuracy: 0.7709 - val_loss: 0.7580 - val_accuracy: 0.5658\n",
            "Epoch 53/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.6235 - accuracy: 0.6696 - val_loss: 1.2406 - val_accuracy: 0.4605\n",
            "Epoch 54/100\n",
            "227/227 [==============================] - 0s 119us/sample - loss: 0.7596 - accuracy: 0.6300 - val_loss: 0.4596 - val_accuracy: 0.7895\n",
            "Epoch 55/100\n",
            "227/227 [==============================] - 0s 90us/sample - loss: 0.4621 - accuracy: 0.7753 - val_loss: 0.4234 - val_accuracy: 0.8026\n",
            "Epoch 56/100\n",
            "227/227 [==============================] - 0s 93us/sample - loss: 0.4134 - accuracy: 0.8062 - val_loss: 0.4334 - val_accuracy: 0.8026\n",
            "Epoch 57/100\n",
            "227/227 [==============================] - 0s 91us/sample - loss: 0.3896 - accuracy: 0.8282 - val_loss: 0.4703 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "227/227 [==============================] - 0s 99us/sample - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.4489 - val_accuracy: 0.7895\n",
            "Epoch 59/100\n",
            "227/227 [==============================] - 0s 93us/sample - loss: 0.3861 - accuracy: 0.8326 - val_loss: 0.4311 - val_accuracy: 0.8289\n",
            "Epoch 60/100\n",
            "227/227 [==============================] - 0s 102us/sample - loss: 0.4106 - accuracy: 0.8282 - val_loss: 0.8280 - val_accuracy: 0.5132\n",
            "Epoch 61/100\n",
            "227/227 [==============================] - 0s 110us/sample - loss: 0.7717 - accuracy: 0.6167 - val_loss: 0.6720 - val_accuracy: 0.6053\n",
            "Epoch 62/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.5221 - accuracy: 0.7489 - val_loss: 0.6641 - val_accuracy: 0.5921\n",
            "Epoch 63/100\n",
            "227/227 [==============================] - 0s 122us/sample - loss: 0.5981 - accuracy: 0.7225 - val_loss: 0.8023 - val_accuracy: 0.5263\n",
            "Epoch 64/100\n",
            "227/227 [==============================] - 0s 101us/sample - loss: 0.7083 - accuracy: 0.6828 - val_loss: 0.6541 - val_accuracy: 0.6447\n",
            "Epoch 65/100\n",
            "227/227 [==============================] - 0s 101us/sample - loss: 0.4618 - accuracy: 0.7533 - val_loss: 0.5518 - val_accuracy: 0.6974\n",
            "Epoch 66/100\n",
            "227/227 [==============================] - 0s 97us/sample - loss: 0.4319 - accuracy: 0.8018 - val_loss: 0.4145 - val_accuracy: 0.8158\n",
            "Epoch 67/100\n",
            "227/227 [==============================] - 0s 112us/sample - loss: 0.3789 - accuracy: 0.8238 - val_loss: 0.4129 - val_accuracy: 0.8289\n",
            "Epoch 68/100\n",
            "227/227 [==============================] - 0s 92us/sample - loss: 0.3700 - accuracy: 0.8590 - val_loss: 0.5039 - val_accuracy: 0.7895\n",
            "Epoch 69/100\n",
            "227/227 [==============================] - 0s 85us/sample - loss: 0.4216 - accuracy: 0.8282 - val_loss: 0.4454 - val_accuracy: 0.8158\n",
            "Epoch 70/100\n",
            "227/227 [==============================] - 0s 102us/sample - loss: 0.4167 - accuracy: 0.8194 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.5075 - accuracy: 0.7533 - val_loss: 0.4801 - val_accuracy: 0.7763\n",
            "Epoch 72/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.3828 - accuracy: 0.8414 - val_loss: 0.5529 - val_accuracy: 0.7105\n",
            "Epoch 73/100\n",
            "227/227 [==============================] - 0s 88us/sample - loss: 0.5121 - accuracy: 0.7313 - val_loss: 0.4859 - val_accuracy: 0.8026\n",
            "Epoch 74/100\n",
            "227/227 [==============================] - 0s 116us/sample - loss: 0.3942 - accuracy: 0.8106 - val_loss: 0.4678 - val_accuracy: 0.8026\n",
            "Epoch 75/100\n",
            "227/227 [==============================] - 0s 86us/sample - loss: 0.3981 - accuracy: 0.8062 - val_loss: 0.4243 - val_accuracy: 0.7763\n",
            "Epoch 76/100\n",
            "227/227 [==============================] - 0s 104us/sample - loss: 0.3870 - accuracy: 0.8370 - val_loss: 0.4771 - val_accuracy: 0.7895\n",
            "Epoch 77/100\n",
            "227/227 [==============================] - 0s 102us/sample - loss: 0.4140 - accuracy: 0.8018 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 78/100\n",
            "227/227 [==============================] - 0s 87us/sample - loss: 0.3683 - accuracy: 0.8326 - val_loss: 0.4663 - val_accuracy: 0.8026\n",
            "Epoch 79/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.3902 - accuracy: 0.8326 - val_loss: 0.4707 - val_accuracy: 0.8026\n",
            "Epoch 80/100\n",
            "227/227 [==============================] - 0s 95us/sample - loss: 0.4322 - accuracy: 0.8018 - val_loss: 0.4854 - val_accuracy: 0.7895\n",
            "Epoch 81/100\n",
            "227/227 [==============================] - 0s 88us/sample - loss: 0.3832 - accuracy: 0.8150 - val_loss: 0.5416 - val_accuracy: 0.7763\n",
            "Epoch 82/100\n",
            "227/227 [==============================] - 0s 86us/sample - loss: 0.4893 - accuracy: 0.7974 - val_loss: 0.4933 - val_accuracy: 0.7895\n",
            "Epoch 83/100\n",
            "227/227 [==============================] - 0s 105us/sample - loss: 0.4940 - accuracy: 0.7885 - val_loss: 0.5305 - val_accuracy: 0.7763\n",
            "Epoch 84/100\n",
            "227/227 [==============================] - 0s 97us/sample - loss: 0.4369 - accuracy: 0.8018 - val_loss: 0.4564 - val_accuracy: 0.7895\n",
            "Epoch 85/100\n",
            "227/227 [==============================] - 0s 86us/sample - loss: 0.3977 - accuracy: 0.8106 - val_loss: 0.6370 - val_accuracy: 0.6316\n",
            "Epoch 86/100\n",
            "227/227 [==============================] - 0s 94us/sample - loss: 0.4318 - accuracy: 0.7753 - val_loss: 0.4164 - val_accuracy: 0.8289\n",
            "Epoch 87/100\n",
            "227/227 [==============================] - 0s 106us/sample - loss: 0.3555 - accuracy: 0.8502 - val_loss: 0.4956 - val_accuracy: 0.7763\n",
            "Epoch 88/100\n",
            "227/227 [==============================] - 0s 100us/sample - loss: 0.4616 - accuracy: 0.7930 - val_loss: 0.4310 - val_accuracy: 0.8158\n",
            "Epoch 89/100\n",
            "227/227 [==============================] - 0s 98us/sample - loss: 0.4926 - accuracy: 0.7445 - val_loss: 0.5895 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "227/227 [==============================] - 0s 102us/sample - loss: 0.4259 - accuracy: 0.7885 - val_loss: 0.5404 - val_accuracy: 0.7763\n",
            "Epoch 91/100\n",
            "227/227 [==============================] - 0s 102us/sample - loss: 0.5591 - accuracy: 0.7401 - val_loss: 0.4361 - val_accuracy: 0.8289\n",
            "Epoch 92/100\n",
            "227/227 [==============================] - 0s 106us/sample - loss: 0.4698 - accuracy: 0.7930 - val_loss: 0.4688 - val_accuracy: 0.8026\n",
            "Epoch 93/100\n",
            "227/227 [==============================] - 0s 92us/sample - loss: 0.7454 - accuracy: 0.7225 - val_loss: 0.7086 - val_accuracy: 0.6316\n",
            "Epoch 94/100\n",
            "227/227 [==============================] - 0s 129us/sample - loss: 0.4869 - accuracy: 0.7885 - val_loss: 0.9228 - val_accuracy: 0.5395\n",
            "Epoch 95/100\n",
            "227/227 [==============================] - 0s 94us/sample - loss: 0.6928 - accuracy: 0.7137 - val_loss: 0.5395 - val_accuracy: 0.7632\n",
            "Epoch 96/100\n",
            "227/227 [==============================] - 0s 98us/sample - loss: 0.3976 - accuracy: 0.8326 - val_loss: 0.5600 - val_accuracy: 0.7632\n",
            "Epoch 97/100\n",
            "227/227 [==============================] - 0s 110us/sample - loss: 0.4438 - accuracy: 0.8106 - val_loss: 0.5526 - val_accuracy: 0.7763\n",
            "Epoch 98/100\n",
            "227/227 [==============================] - 0s 111us/sample - loss: 0.5626 - accuracy: 0.7269 - val_loss: 0.5924 - val_accuracy: 0.6974\n",
            "Epoch 99/100\n",
            "227/227 [==============================] - 0s 106us/sample - loss: 0.4176 - accuracy: 0.7974 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "227/227 [==============================] - 0s 95us/sample - loss: 0.3559 - accuracy: 0.8238 - val_loss: 0.4329 - val_accuracy: 0.8289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmewsB9Aq8i",
        "colab_type": "code",
        "outputId": "2aea77de-1747-45c3-92db-16a3bd46fb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data, test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "76/76 [==============================] - 0s 208us/sample - loss: 0.4329 - accuracy: 0.8289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBsBaqfA1QR",
        "colab_type": "code",
        "outputId": "a3fdf658-ae62-43fc-f684-be024e30bbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predictions_list = []\n",
        "predictions = model.predict(test_data)\n",
        "for i in range (0,len(test_label)):\n",
        "  predictions_list.append(round(predictions[i][0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scq5xPMQA38O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yelDEPMVqLY",
        "colab_type": "code",
        "outputId": "701b4d0c-a6f8-4a66-d0b4-6f09508952ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_score(predictions_list, test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8289473684210527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDQ4vkzlf5sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}